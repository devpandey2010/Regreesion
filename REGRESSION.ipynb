{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1.- What is Simple Linear Regression?\n",
        "   \n",
        "   \n",
        "   Regression means establishing   and analysing realtionship between two or more variables. when we say simple it means between two variable and linear means direct relationship or inverse relationship.Thus regression helps to predict the dependent variable with change in independent variable."
      ],
      "metadata": {
        "id": "SvEoIwKBpGrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2.)- What are the key assumptions of Simple Linear Regression?\n",
        "\n",
        "\n",
        "ASSUMPTIONS:                              \n",
        "1.LINEARITY:Independent and Dependent variable should have linear realtion.\n",
        "\n",
        "2.INDEPENDECE:The Observation(rows)should be independent of each other.Since observations are independent the errors should be independent.\n",
        "\n",
        "3.Homoscedasticity:It is also known as constant variance.The variance of errors are constant.\n",
        "\n",
        "4.Normality of errors:Errors should be Normally distributed\n",
        "\n",
        "5.The features should not be related or should have least relation beacsue it is simple linear regression not multi."
      ],
      "metadata": {
        "id": "XbNacEMtqzGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. What does the coefficient m represent in the equation Y=mX+c?\n",
        "\n",
        "The coefficient m in the equation Y=mx+c represent slope.mathematically slope is defined as change in y with respect to x.\n",
        "In simple linear Regression slope and intercept decides the acuuracy of model or with optimised m and c which we get by gradient descent we can get the best fit line."
      ],
      "metadata": {
        "id": "Xe8tXXXYtEAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. What does the coefficient m represent in the equation Y=mX+c?\n",
        "\n",
        "The coefficient c represent in equation represent intercept.intercept is the  point where line cuts the y axis."
      ],
      "metadata": {
        "id": "7ujYTaxzt7Yg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5- How do we calculate the slope m in Simple Linear Regression?\n",
        "\n",
        "We calculate slope in simple linear regression by calculating change in dependent variable with respect to change in independent variable.\n",
        "m=(y2-y1)/(x2-x1),where y2,y1 are depenedent variables and x2,x1 are independent variables."
      ],
      "metadata": {
        "id": "-4KemCnculdN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6.What is the purpose of the least squares method in Simple Linear Regression?\n",
        "\n",
        "The purpose of least square error is to minimise the error,and to find the best fit line for a set of data. This is known convergence theorem, error is minimised by gradient decent method"
      ],
      "metadata": {
        "id": "GvX_GrLXt7cG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. How is the coefficient of determination (RÂ²) interpreted in Simple Linear Regression?\n",
        "\n",
        "\n",
        "ANS-> R square is defined as percentage variation in y explained by x.\n",
        "R^2 =SSR/TSS ,where SSR is sum of squared error ie the explained variation by the model,and TSS is total variation .\n",
        "On terms of unexplained variation it is defined as 1-(RSS/TSS),where RSS is unexpalined variation by model."
      ],
      "metadata": {
        "id": "tbmVQVX_t7fj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. What is Multiple Linear Regression?\n",
        "\n",
        "ANS->Multiple Linear Regression defined as linear reagression when there are multiple features or there  are more than two independent variable and one target variable."
      ],
      "metadata": {
        "id": "FPUQnrMyxzf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. What is the main difference between Simple and Multiple Linear Regression?\n",
        "\n",
        "In simple linear regression the target varible depends on one independent variable,while in multiple linar regression there are multiple features on which target variable depends on.\n"
      ],
      "metadata": {
        "id": "zvInALO5xzjm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. What are the key assumptions of Multiple Linear Regression?\n",
        "\n",
        "\n",
        "Linear relationship: The dependent variable and the independent variables have a linear relationship.\n",
        "\n",
        "Homoscedasticity: The variance of the residuals is consistent across all levels of the independent variables.\n",
        "\n",
        "Independence: The residuals are not correlated with each other.\n",
        "\n",
        "Normality: The errors are normally distributed.\n",
        "\n",
        "No multicollinearity: The predictor variables are not highly correlated with each other.\n"
      ],
      "metadata": {
        "id": "byl5Sl3Oxzm7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?\n",
        "\n",
        "\n",
        "Heteroskedasticity is when the variance of the residuals in a regression model varies widely. This can be seen in a residual plot as a fan or cone shape.\n",
        "\n",
        "Heteroskedasticity can make the results of a multiple linear regression model invalid. It can also make the F-test for overall significance and t-tests for individual coefficients unreliable.\n",
        "\n"
      ],
      "metadata": {
        "id": "f_i0cidjxzqo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q12. How can you improve a Multiple Linear Regression model with high multicollinearity?\n",
        "\n",
        "To improve a multiple linear regression model with high multicollinearity we have VIF(variation inflation factor)and if VIF>=10 the we can drop the feature one by one.\n",
        "Secondly since measuring VIF and droping features one by one is time taking process the we have RFE(Recursive feature Elimination).By this two process we can improve a model with high multicollinearity,.\n"
      ],
      "metadata": {
        "id": "Mii7W9ThxzuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q13. What are some common techniques for transforming categorical variables for use in regression models?\n",
        "\n",
        "For transfroming categorical variables use in regression models we have data encoding\n",
        "1.Nominal/one hot encoding->its does not follow any orders every individual observation are independent of each other.A technique that transforms categorical variables into binary vectors. Each category is assigned a binary value of 1 or 0, depending on whether that category is present.\n",
        "\n",
        "2.Label and Ordinal encoding->assigns Numeric data to each category.\n",
        "\n",
        "3.Target guided ordinal encoding"
      ],
      "metadata": {
        "id": "bJJcL_JQxzx5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q14. What is the role of interaction terms in Multiple Linear Regression?\n",
        "\n",
        "\n",
        " Interaction terms enable you to examine whether the relationship between the target and the independent variable changes depending on the value of another independent variable.\n"
      ],
      "metadata": {
        "id": "8FyBR9hKxz1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q15. How can the interpretation of\n",
        "intercept differ between Simple and Multiple Linear Regression?\n",
        "\n",
        "Ans->In simple linear Regression itercept is the point where the line cuts the x-axis but in mutliple linear Regression there is no line due to multiple features its a hyper plane and the point at which this hyperplane cuts the x-axis is intercept in case of multiple linear regression."
      ],
      "metadata": {
        "id": "gatwr0s3xz40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q16. What is the significance of the slope in regression analysis, and how does it affect predictions?\n",
        "\n",
        "In regression analysis slope determine\n",
        "the rate at which our prediction increase/decrease with one unit increase/decrease.sign of slope determine whether it will increase or decrease.\n",
        "In regression analysis, the slope of a line shows how much the dependent variable changes for each unit change in the independent variable. The slope is important because it indicates the strength of the relationship between the two variables and how well the independent variable can predict the dependent variable.\n"
      ],
      "metadata": {
        "id": "dkb4xwqpxz8D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q17. How does the intercept in a regression model provide context for the relationship between variables?\n",
        "\n",
        "The intercept in a regression model provides context for the relationship between variables by representing the value of the dependent variable when the independent variable is zero. This can be useful for understanding the relationship between the variables in a real-world context.\n",
        "The intercept can be used to understand the relationship between the variables in a real-world context. For example, in a manufacturing cost model, the intercept represents the fixed costs when no units are produced."
      ],
      "metadata": {
        "id": "fGgayHdhxz_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q18.What are the limitations of using RÂ² as a sole measure of model performance?\n",
        "\n",
        "Ans->Doesn't measure goodness of fit: (R^2) doesn't tell you if your model is good or bad.\n",
        "Doesn't measure predictive error: (R^2) doesn't tell you how well your model predicts future outcomes.\n",
        "Doesn't measure how variables relate: (R^2) doesn't tell you how one variable explains another.\n",
        "Doesn't detect non-linear relationships: (R^2) can give misleading results when working with non-linear relationships or smaller datasets.Doesn't indicate bias: (R^{2}) doesn't tell you if your model's coefficient estimates and predictions are biased.\n",
        "Can be misleading: (R^2) can give a high value for a poorly fitted model, or a low value for a good model."
      ],
      "metadata": {
        "id": "2njjA9pQx0Cv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q19.How would you interpret a large standard error for a regression coefficient?\n",
        "\n",
        "Ans->A large standard error for a regression coefficient indicates that the estimated coefficient is less precise and has a higher degree of variability, meaning there is less confidence in the true population value of that coefficient based on the sample data; essentially, if you were to repeat the study with different samples, the estimated coefficient could vary significantly from one sample to another.\n",
        "\n"
      ],
      "metadata": {
        "id": "XsCizIVrx0F_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q20. How can heteroscedasticity be identified in residual plots, and why is it important to address it?\n",
        "\n",
        "ans->Heteroscedasticity can be identified in residual plots it the shape of plot is not constant or it has funnel shape or a variation.\n",
        "Heteroscedasticity can invalidate statistical tests of significance\n",
        "like f test.\n",
        "It can lead to inaccurate predictions\n",
        "It can make it difficult to understand the relationships between variables"
      ],
      "metadata": {
        "id": "xByfM9NDIqmo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q21.What does it mean if a Multiple Linear Regression model has a high RÂ² but low adjusted RÂ²?\n",
        "\n",
        "Ans->R2 is explained variation of total variation.If r2 is high the we may say it is a good model.when we add features R2 may increase or remain constant.\n",
        "adjusted R2 tells whether on adding a feature R2 increases or not.If a model Has high r2 and low adjusted R2,the it means on adding that featuresit will not contribute to the model performance and hence we should not add that features.\n"
      ],
      "metadata": {
        "id": "E-gH_iR7Iqpw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q22.Why is it important to scale variables in Multiple Linear Regression?\n",
        "\n",
        "Ans->Scaling is a optional technique in model and it doesnot affect the distribution.on scaling data all features get scaled on same level which makes it easy to interpret.It also improves optimization process,and also improves model performance.\n"
      ],
      "metadata": {
        "id": "6h4pd746Iqsq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q23.What is polynomial regression?\n",
        "\n",
        "Ans->Polynomial regression defines the non linear realationship between the variables.\n",
        "Polynomial regression is a machine learning algorithm that models the relationship between variables using a polynomial function. It's used when linear regression models aren't adequate to capture the complexity of the relationship between the variables."
      ],
      "metadata": {
        "id": "0bY2IDttIqvy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q24.How does polynomial regression differ from linear regression?\n",
        "\n",
        "Ans->Linear Regression is a machine Learning algorithm which can measure an linear realtionship between the variables while polynomial regression can measure the non linear Realtionship bteween the variables."
      ],
      "metadata": {
        "id": "CeOJN85CIqy6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q25.When is polynomial regression used?\n",
        "\n",
        "Ans->Polynomial regression is used to measure non linear realtionship and more complex relation between independent and dependent variables by usinf power like cube square.\n"
      ],
      "metadata": {
        "id": "tk6Cwk1mIq18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q26. What is the general equation for polynomial regression?\n",
        "\n",
        "Ans->Y=m0+m1X+m2X^2+m3X^3+......+mnX^n+c\n",
        "X: The independent variable\n",
        "Y: The dependent variable\n",
        "mi: The coefficients of the respective degrees of the independent variables\n",
        "c: The intercept\n",
        "n: The degree of the polynomial"
      ],
      "metadata": {
        "id": "tAuYMhHRIq5E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q27.Can polynomial regression be applied to multiple variables?\n",
        "\n",
        "Ans->Yes,Polynomial Regression can be applied to multiple Regression and it is known as Multiple polynomial Regression."
      ],
      "metadata": {
        "id": "f1DrTkhSIq7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q28.What are the limitations of polynomial regression?\n",
        "\n",
        "ans->Overfitting\n",
        "A model can overfit the training data, meaning it fits the noise in the data instead of the underlying trend. This can lead to poor predictions on new data.\n",
        "Computational complexity\n",
        "High-degree polynomials can be computationally expensive, especially with large datasets.\n",
        "\n",
        "Selecting the right degree\n",
        "Choosing the right degree for the polynomial can be challenging. A low-degree polynomial may underfit the data, while a high-degree polynomial risks overfitting.\n",
        "\n",
        "Sensitivity to outliers\n",
        "A single outlier can significantly impact the results of polynomial regression.\n",
        "\n",
        "Data requirements\n",
        "Small datasets may not provide enough information to reliably estimate the complex polynomial terms.\n",
        "\n",
        "Poor generalization\n",
        "A model that overfits the training data may not generalize well to new data.\n"
      ],
      "metadata": {
        "id": "I-IVeiy3Iq_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q29.What methods can be used to evaluate model fit when selecting the degree of a polynomial?\n",
        "\n",
        "ans->Visual inspection\n",
        "Plot the data with different degrees to find a degree that fits well without being too complex.\n",
        "Look for patterns in the data to help you choose the degree.\n",
        "\n",
        "Cross-validation\n",
        "Split the data into training and validation sets.\n",
        "Fit different degrees to the training set and evaluate the performance on the validation set.\n",
        "Choose the degree that performs best on the validation set.\n",
        "\n",
        "Forward or backward selection\n",
        "Increase the degree of the polynomial until it's significant enough to define the best model.\n",
        "Decrease the degree of the polynomial until it's significant enough to define the best model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ReU_Q5fyIrCm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q30.Why is visualization important in polynomial regression?\n",
        "\n",
        "Ans->Visualization is important in polynomial regression as plotting the data with different degree to find a degree that fits well without being too complex.\n"
      ],
      "metadata": {
        "id": "6vBe0R62U5ag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q31.How is polynomial regression implemented in Python"
      ],
      "metadata": {
        "id": "8PFBfF_rVV74"
      }
    }
  ]
}